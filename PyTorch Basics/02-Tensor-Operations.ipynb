{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <center>Tensor Operations</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing\n",
    "Extracting specific values from a tensor works just the same as with NumPy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(9).reshape(3,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n",
      "tensor([3, 4, 5])\n",
      "tensor([[1],\n",
      "        [4],\n",
      "        [7]])\n",
      "tensor([[1, 2],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "print(x[2,2]) # Grabbing a single element\n",
    "print(x[1, :]) # Grabbing a line\n",
    "print(x[:, 1:2]) # Grabbing a column (like this should be done)\n",
    "print(x[:2, 1:]) # Grabbing a sub-tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape tensors with <tt>.view()</tt>\n",
    "<a href='https://pytorch.org/docs/master/tensors.html#torch.Tensor.view'><strong><tt>view()</tt></strong></a> and <a href='https://pytorch.org/docs/master/torch.html#torch.reshape'><strong><tt>reshape()</tt></strong></a> do essentially the same thing by returning a reshaped tensor without changing the original tensor in place.<br>\n",
    "There's a good discussion of the differences <a href='https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch'>here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x is unchanged, unless it is reassigned to the reshaped vector.\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Views reflect the most current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[234,   1,   2,   3,   4],\n",
      "        [  5,   6,   7,   8,   9]])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(2,5)\n",
    "x[0]=234\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Views can infer the correct size\n",
    "By passing in <tt>-1</tt> PyTorch will infer the correct value from the given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[234,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2,-1) # Infers (2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[234,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1,5) # Infers (2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adopt another tensor's shape with <tt>.view_as()</tt>\n",
    "<a href='https://pytorch.org/docs/master/tensors.html#torch.Tensor.view_as'><strong><tt>view_as(input)</tt></strong></a> only works with tensors that have the same number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[234,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view_as(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Arithmetic\n",
    "Adding tensors can be performed a few different ways depending on the desired result.<br>\n",
    "\n",
    "As a simple expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n",
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(a + b)\n",
    "print(torch.add(a, b)) # As arguments passed into a torch operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an output tensor passed in as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(3)\n",
    "torch.add(a, b, out=result)  # equivalent to result=torch.add(a,b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing a tensor in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "a.add_(b)  # equivalent to a=torch.add(a,b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> Any operation that changes a tensor in-place is post-fixed with an underscore _.\n",
    "\n",
    "In the above example: <tt>a.add_(b)</tt> changed <tt>a</tt>.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(np.arange(0.,9.,1)).reshape(3,3)\n",
    "b = torch.tensor(np.linspace(0,18.,9)).reshape(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Tensor Operations\n",
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Arithmetic</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>a + b</td><td>a.add(b)</td><td>element wise addition</td></tr>\n",
    "<tr><td>a - b</td><td>a.sub(b)</td><td>subtraction</td></tr>\n",
    "<tr><td>a * b</td><td>a.mul(b)</td><td>multiplication</td></tr>\n",
    "<tr><td>a / b</td><td>a.div(b)</td><td>division</td></tr>\n",
    "<tr><td>a % b</td><td>a.fmod(b)</td><td>modulo (remainder after division)</td></tr>\n",
    "<tr><td>a<sup>b</sup></td><td>a.pow(b)</td><td>power</td></tr>\n",
    "<tr><td>&nbsp;</td><td></td><td></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  3.2500,  6.5000],\n",
      "        [ 9.7500, 13.0000, 16.2500],\n",
      "        [19.5000, 22.7500, 26.0000]], dtype=torch.float64)\n",
      "tensor([[  0.0000,  -1.2500,  -2.5000],\n",
      "        [ -3.7500,  -5.0000,  -6.2500],\n",
      "        [ -7.5000,  -8.7500, -10.0000]], dtype=torch.float64)\n",
      "tensor([[  0.0000,   2.2500,   9.0000],\n",
      "        [ 20.2500,  36.0000,  56.2500],\n",
      "        [ 81.0000, 110.2500, 144.0000]], dtype=torch.float64)\n",
      "tensor([[   nan, 0.4444, 0.4444],\n",
      "        [0.4444, 0.4444, 0.4444],\n",
      "        [0.4444, 0.4444, 0.4444]], dtype=torch.float64)\n",
      "tensor([[1.0000e+00, 1.0000e+00, 2.2627e+01],\n",
      "        [1.6618e+03, 2.6214e+05, 7.3015e+07],\n",
      "        [3.1992e+10, 2.0431e+13, 1.8014e+16]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(a+b)\n",
    "print(a-b)\n",
    "print(a*b)\n",
    "print(a/b)\n",
    "print(a.pow(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Monomial Operations</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>|a|</td><td>torch.abs(a)</td><td>absolute value</td></tr>\n",
    "<tr><td>1/a</td><td>torch.reciprocal(a)</td><td>reciprocal</td></tr>\n",
    "<tr><td>\\sqrt{a}</td><td>torch.sqrt(a)</td><td>square root</td></tr>\n",
    "<tr><td>log(a)</td><td>torch.log(a)</td><td>natural log</td></tr>\n",
    "<tr><td>e<sup>a</sup></td><td>torch.exp(a)</td><td>exponential</td></tr>\n",
    "<tr><td>12.34  ==>  12.</td><td>torch.trunc(a)</td><td>truncated integer</td></tr>\n",
    "<tr><td>12.34  ==>  0.34</td><td>torch.frac(a)</td><td>fractional component</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]], dtype=torch.float64)\n",
      "tensor([[   inf, 1.0000, 0.5000],\n",
      "        [0.3333, 0.2500, 0.2000],\n",
      "        [0.1667, 0.1429, 0.1250]], dtype=torch.float64)\n",
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  9., 11.],\n",
      "        [13., 15., 18.]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.2500, 0.5000],\n",
      "        [0.7500, 0.0000, 0.2500],\n",
      "        [0.5000, 0.7500, 0.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(a.abs())\n",
    "print(a.reciprocal())\n",
    "print(b.trunc())\n",
    "print(b.frac())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Trigonometry</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>sin(a)</td><td>torch.sin(a)</td><td>sine</td></tr>\n",
    "<tr><td>cos(a)</td><td>torch.sin(a)</td><td>cosine</td></tr>\n",
    "<tr><td>tan(a)</td><td>torch.sin(a)</td><td>tangent</td></tr>\n",
    "<tr><td>arcsin(a)</td><td>torch.asin(a)</td><td>arc sine</td></tr>\n",
    "<tr><td>arccos(a)</td><td>torch.acos(a)</td><td>arc cosine</td></tr>\n",
    "<tr><td>arctan(a)</td><td>torch.atan(a)</td><td>arc tangent</td></tr>\n",
    "<tr><td>sinh(a)</td><td>torch.sinh(a)</td><td>hyperbolic sine</td></tr>\n",
    "<tr><td>cosh(a)</td><td>torch.cosh(a)</td><td>hyperbolic cosine</td></tr>\n",
    "<tr><td>tanh(a)</td><td>torch.tanh(a)</td><td>hyperbolic tangent</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Summary Statistics</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>$\\sum a$</td><td>torch.sum(a)</td><td>sum</td></tr>\n",
    "<tr><td>$\\bar a$</td><td>torch.mean(a)</td><td>mean</td></tr>\n",
    "<tr><td>a<sub>max</sub></td><td>torch.max(a)</td><td>maximum</td></tr>\n",
    "<tr><td>a<sub>min</sub></td><td>torch.min(a)</td><td>minimum</td></tr>\n",
    "<tr><td colspan=\"3\">torch.max(a,b) returns a tensor of size a<br>containing the element wise max between a and b</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(81., dtype=torch.float64)\n",
      "tensor(9., dtype=torch.float64)\n",
      "tensor(8., dtype=torch.float64) tensor(0., dtype=torch.float64)\n",
      "tensor([[ 0.0000,  2.2500,  4.5000],\n",
      "        [ 6.7500,  9.0000, 11.2500],\n",
      "        [13.5000, 15.7500, 18.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(b.sum())\n",
    "print(b.mean())\n",
    "print(a.max(), a.min())\n",
    "print(a.max(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> Most arithmetic operations require float values. Those that do work with integers return integer tensors.<br>\n",
    "For example, <tt>torch.div(a,b)</tt> performs floor division (truncates the decimal) for integer types, and classic division for floats.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot products\n",
    "Dot products can be expressed as <a href='https://pytorch.org/docs/stable/torch.html#torch.dot'><strong><tt>torch.dot(a,b)</tt></strong></a> or `a.dot(b)` or `b.dot(a)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 10., 18.])\n",
      "\n",
      "tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(a.mul(b)) # for reference\n",
    "print()\n",
    "print(a.dot(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> There's a slight difference between <tt>torch.dot()</tt> and <tt>numpy.dot()</tt>. While <tt>torch.dot()</tt> only accepts 1D arguments and returns a dot product, <tt>numpy.dot()</tt> also accepts 2D arguments and performs matrix multiplication. We show matrix multiplication below.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication\n",
    "2D <a href='https://en.wikipedia.org/wiki/Matrix_multiplication'>Matrix multiplication</a> is possible when the number of columns in tensor <strong><tt>A</tt></strong> matches the number of rows in tensor <strong><tt>B</tt></strong>. In this case, the product of tensor <strong><tt>A</tt></strong> with size $(x,y)$ and tensor <strong><tt>B</tt></strong> with size $(y,z)$ results in a tensor of size $(x,z)$\n",
    "\n",
    "\n",
    "$\\begin{bmatrix} a & b & c \\\\\n",
    "d & e & f \\end{bmatrix} \\;\\times\\; \\begin{bmatrix} m & n \\\\ p & q \\\\ r & s \\end{bmatrix} = \\begin{bmatrix} (am+bp+cr) & (an+bq+cs) \\\\\n",
    "(dm+ep+fr) & (dn+eq+fs) \\end{bmatrix}$</div></div>\n",
    "\n",
    "Matrix multiplication can be computed using <a href='https://pytorch.org/docs/stable/torch.html#torch.mm'><strong><tt>torch.mm(a,b)</tt></strong></a> or `a.mm(b)` or `a @ b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([2, 3])\n",
      "b:  torch.Size([3, 2])\n",
      "a x b:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0,2,4],[1,3,5]], dtype=torch.float)\n",
    "b = torch.tensor([[6,7],[8,9],[10,11]], dtype=torch.float)\n",
    "\n",
    "print('a: ',a.size())\n",
    "print('b: ',b.size())\n",
    "print('a x b: ',torch.mm(a,b).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n",
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n",
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.mm(a,b))\n",
    "print(a.mm(b))\n",
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication with broadcasting\n",
    "Matrix multiplication that involves <a href='https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics'>broadcasting</a> can be computed using <a href='https://pytorch.org/docs/stable/torch.html#torch.matmul'><strong><tt>torch.matmul(a,b)</tt></strong></a> or `a.matmul(b)` or `a @ b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn(2, 3, 4)\n",
    "t2 = torch.randn(4, 5)\n",
    "\n",
    "print(torch.matmul(t1, t2).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the same operation raises a <tt><strong>RuntimeError</strong></tt> with <tt>torch.mm()</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 3D, 2D tensors at ..\\aten\\src\\TH/generic/THTensorMath.cpp:956",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18028\\2270689567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: matrices expected, got 3D, 2D tensors at ..\\aten\\src\\TH/generic/THTensorMath.cpp:956"
     ]
    }
   ],
   "source": [
    "print(torch.mm(t1, t2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 or Euclidian Norm\n",
    "See <a href='https://pytorch.org/docs/stable/torch.html#torch.norm'><strong><tt>torch.norm()</tt></strong></a>\n",
    "\n",
    "The <a href='https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm'>Euclidian Norm</a> gives the vector norm of $x$ where $x=(x_1,x_2,...,x_n)$.<br>\n",
    "It is calculated as<br>\n",
    "\n",
    "${\\displaystyle \\left\\|{\\boldsymbol {x}}\\right\\|_{2}:={\\sqrt {x_{1}^{2}+\\cdots +x_{n}^{2}}}}$\n",
    "\n",
    "\n",
    "When applied to a matrix, <tt>torch.norm()</tt> returns the <a href='https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm'>Frobenius norm</a> by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([2.,5.,8.,14.])\n",
    "x.norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of elements\n",
    "See <a href='https://pytorch.org/docs/stable/torch.html#torch.numel'><strong><tt>torch.numel()</tt></strong></a>\n",
    "\n",
    "Returns the number of elements in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3,7)\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be useful in certain calculations like Mean Squared Error:<br>\n",
    "<tt>\n",
    "def mse(t1, t2):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;diff = t1 - t2<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;return torch.sum(diff * diff) / diff<strong>.numel()</strong></tt>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('pytorchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2844142bb07d73a214d96737b2c623458c43f59df188e7e149346c31d83c928"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

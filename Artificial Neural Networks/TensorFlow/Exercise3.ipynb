{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>ANN Customer Churn prediction</center>\n",
    "\n",
    "\n",
    "**The DataSet context is the following:** \n",
    "\n",
    "\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\" [IBM Sample Data Sets]\n",
    "\n",
    "**Content**\n",
    "\n",
    "Each row represents a customer, each column contains customer’s attributes described on the column Metadata.\n",
    "\n",
    "The data set includes information about:\n",
    "\n",
    "- Customers who left within the last month – the column is called Churn\n",
    "- Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "- Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
    "- Demographic info about customers – gender, age range, and if they have partners and dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/Lenovo/Desktop/Python/Neural Networks/Data Sets/TensorFlow/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   gender            7043 non-null   object \n",
      " 1   SeniorCitizen     7043 non-null   int64  \n",
      " 2   Partner           7043 non-null   object \n",
      " 3   Dependents        7043 non-null   object \n",
      " 4   tenure            7043 non-null   int64  \n",
      " 5   PhoneService      7043 non-null   object \n",
      " 6   MultipleLines     7043 non-null   object \n",
      " 7   InternetService   7043 non-null   object \n",
      " 8   OnlineSecurity    7043 non-null   object \n",
      " 9   OnlineBackup      7043 non-null   object \n",
      " 10  DeviceProtection  7043 non-null   object \n",
      " 11  TechSupport       7043 non-null   object \n",
      " 12  StreamingTV       7043 non-null   object \n",
      " 13  StreamingMovies   7043 non-null   object \n",
      " 14  Contract          7043 non-null   object \n",
      " 15  PaperlessBilling  7043 non-null   object \n",
      " 16  PaymentMethod     7043 non-null   object \n",
      " 17  MonthlyCharges    7043 non-null   float64\n",
      " 18  TotalCharges      7043 non-null   object \n",
      " 19  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(17)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=\"customerID\", inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = df[\"TotalCharges\"] == ' '\n",
    "empty_index = df[\"TotalCharges\"][filt].index\n",
    "\n",
    "df.drop(index=empty_index, inplace=True)\n",
    "\n",
    "df[\"TotalCharges\"] = df[\"TotalCharges\"].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 412x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.displot(data=df, x=\"tenure\", hue=\"Churn\", kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 412x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.displot(data=df, x=\"MonthlyCharges\", hue=\"Churn\", kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: ['Female' 'Male']\n",
      "Partner: ['Yes' 'No']\n",
      "Dependents: ['No' 'Yes']\n",
      "PhoneService: ['No' 'Yes']\n",
      "MultipleLines: ['No phone service' 'No' 'Yes']\n",
      "InternetService: ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity: ['No' 'Yes' 'No internet service']\n",
      "OnlineBackup: ['Yes' 'No' 'No internet service']\n",
      "DeviceProtection: ['No' 'Yes' 'No internet service']\n",
      "TechSupport: ['No' 'Yes' 'No internet service']\n",
      "StreamingTV: ['No' 'Yes' 'No internet service']\n",
      "StreamingMovies: ['No' 'Yes' 'No internet service']\n",
      "Contract: ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling: ['Yes' 'No']\n",
      "PaymentMethod: ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "Churn: ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns\n",
    "\n",
    "for col in columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('No phone service', \"No\", inplace=True)\n",
    "df.replace('No internet service', \"No\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender: ['Female' 'Male']\n",
      "Partner: ['Yes' 'No']\n",
      "Dependents: ['No' 'Yes']\n",
      "PhoneService: ['No' 'Yes']\n",
      "MultipleLines: ['No' 'Yes']\n",
      "InternetService: ['DSL' 'Fiber optic' 'No']\n",
      "OnlineSecurity: ['No' 'Yes']\n",
      "OnlineBackup: ['Yes' 'No']\n",
      "DeviceProtection: ['No' 'Yes']\n",
      "TechSupport: ['No' 'Yes']\n",
      "StreamingTV: ['No' 'Yes']\n",
      "StreamingMovies: ['No' 'Yes']\n",
      "Contract: ['Month-to-month' 'One year' 'Two year']\n",
      "PaperlessBilling: ['Yes' 'No']\n",
      "PaymentMethod: ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
      " 'Credit card (automatic)']\n",
      "Churn: ['No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "for col in columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_map = {\n",
    "    \"Yes\": 1,\n",
    "    \"No\": 0\n",
    "}\n",
    "\n",
    "yes_no_cols = df.select_dtypes(\"object\").drop(columns=[\"gender\", \"InternetService\", \"Contract\", \"PaymentMethod\"]).columns\n",
    "\n",
    "for c in yes_no_cols:\n",
    "    df[c] = df[c].map(my_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"].replace({\"Female\": 0, \"Male\":1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7032 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "0          0              0        1           0       1             0   \n",
       "1          1              0        0           0      34             1   \n",
       "2          1              0        0           0       2             1   \n",
       "3          1              0        0           0      45             0   \n",
       "4          0              0        0           0       2             1   \n",
       "...      ...            ...      ...         ...     ...           ...   \n",
       "7038       1              0        1           1      24             1   \n",
       "7039       0              0        1           1      72             1   \n",
       "7040       0              0        1           1      11             0   \n",
       "7041       1              1        1           0       4             1   \n",
       "7042       1              0        0           0      66             1   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  ...  \\\n",
       "0                 0               0             1                 0  ...   \n",
       "1                 0               1             0                 1  ...   \n",
       "2                 0               1             1                 0  ...   \n",
       "3                 0               1             0                 1  ...   \n",
       "4                 0               0             0                 0  ...   \n",
       "...             ...             ...           ...               ...  ...   \n",
       "7038              1               1             0                 1  ...   \n",
       "7039              1               0             1                 1  ...   \n",
       "7040              0               1             0                 0  ...   \n",
       "7041              1               0             0                 0  ...   \n",
       "7042              0               1             0                 1  ...   \n",
       "\n",
       "      MonthlyCharges  TotalCharges  Churn  InternetService_Fiber optic  \\\n",
       "0              29.85         29.85      0                            0   \n",
       "1              56.95       1889.50      0                            0   \n",
       "2              53.85        108.15      1                            0   \n",
       "3              42.30       1840.75      0                            0   \n",
       "4              70.70        151.65      1                            1   \n",
       "...              ...           ...    ...                          ...   \n",
       "7038           84.80       1990.50      0                            0   \n",
       "7039          103.20       7362.90      0                            1   \n",
       "7040           29.60        346.45      0                            0   \n",
       "7041           74.40        306.60      1                            1   \n",
       "7042          105.65       6844.50      0                            1   \n",
       "\n",
       "      InternetService_No  Contract_One year  Contract_Two year  \\\n",
       "0                      0                  0                  0   \n",
       "1                      0                  1                  0   \n",
       "2                      0                  0                  0   \n",
       "3                      0                  1                  0   \n",
       "4                      0                  0                  0   \n",
       "...                  ...                ...                ...   \n",
       "7038                   0                  1                  0   \n",
       "7039                   0                  1                  0   \n",
       "7040                   0                  0                  0   \n",
       "7041                   0                  0                  0   \n",
       "7042                   0                  0                  1   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                         0                               1   \n",
       "1                                         0                               0   \n",
       "2                                         0                               0   \n",
       "3                                         0                               0   \n",
       "4                                         0                               1   \n",
       "...                                     ...                             ...   \n",
       "7038                                      0                               0   \n",
       "7039                                      1                               0   \n",
       "7040                                      0                               1   \n",
       "7041                                      0                               0   \n",
       "7042                                      0                               0   \n",
       "\n",
       "      PaymentMethod_Mailed check  \n",
       "0                              0  \n",
       "1                              1  \n",
       "2                              1  \n",
       "3                              0  \n",
       "4                              0  \n",
       "...                          ...  \n",
       "7038                           1  \n",
       "7039                           0  \n",
       "7040                           0  \n",
       "7041                           1  \n",
       "7042                           0  \n",
       "\n",
       "[7032 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.get_dummies(df, drop_first=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(columns=\"Churn\").values\n",
    "y = df1[\"Churn\"].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 1s 16ms/step - loss: 0.6747 - accuracy: 0.5719 - val_loss: 0.5966 - val_accuracy: 0.7399\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.5740 - accuracy: 0.7300 - val_loss: 0.5395 - val_accuracy: 0.7505\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7330 - val_loss: 0.5077 - val_accuracy: 0.7612\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7477 - val_loss: 0.4826 - val_accuracy: 0.7811\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7687 - val_loss: 0.4639 - val_accuracy: 0.7804\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7781 - val_loss: 0.4515 - val_accuracy: 0.7946\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7836 - val_loss: 0.4433 - val_accuracy: 0.7960\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7844 - val_loss: 0.4385 - val_accuracy: 0.7967\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7877 - val_loss: 0.4353 - val_accuracy: 0.8010\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.7895 - val_loss: 0.4332 - val_accuracy: 0.8045\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7920 - val_loss: 0.4316 - val_accuracy: 0.8031\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7913 - val_loss: 0.4302 - val_accuracy: 0.8053\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7948 - val_loss: 0.4289 - val_accuracy: 0.8074\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7938 - val_loss: 0.4280 - val_accuracy: 0.8045\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7943 - val_loss: 0.4269 - val_accuracy: 0.8053\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7956 - val_loss: 0.4261 - val_accuracy: 0.8067\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7961 - val_loss: 0.4256 - val_accuracy: 0.8053\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7956 - val_loss: 0.4252 - val_accuracy: 0.8045\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7979 - val_loss: 0.4245 - val_accuracy: 0.8053\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7975 - val_loss: 0.4244 - val_accuracy: 0.8031\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7979 - val_loss: 0.4236 - val_accuracy: 0.8053\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7984 - val_loss: 0.4232 - val_accuracy: 0.8074\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8000 - val_loss: 0.4231 - val_accuracy: 0.8095\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7995 - val_loss: 0.4224 - val_accuracy: 0.8088\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8005 - val_loss: 0.4223 - val_accuracy: 0.8081\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7996 - val_loss: 0.4221 - val_accuracy: 0.8081\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8005 - val_loss: 0.4218 - val_accuracy: 0.8088\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7993 - val_loss: 0.4215 - val_accuracy: 0.8081\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8021 - val_loss: 0.4212 - val_accuracy: 0.8060\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8004 - val_loss: 0.4210 - val_accuracy: 0.8074\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8012 - val_loss: 0.4209 - val_accuracy: 0.8074\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8012 - val_loss: 0.4207 - val_accuracy: 0.8109\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8005 - val_loss: 0.4207 - val_accuracy: 0.8074\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8002 - val_loss: 0.4205 - val_accuracy: 0.8081\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.8011 - val_loss: 0.4203 - val_accuracy: 0.8081\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7995 - val_loss: 0.4201 - val_accuracy: 0.8109\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8007 - val_loss: 0.4200 - val_accuracy: 0.8109\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8002 - val_loss: 0.4198 - val_accuracy: 0.8095\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8005 - val_loss: 0.4198 - val_accuracy: 0.8088\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8000 - val_loss: 0.4197 - val_accuracy: 0.8102\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8000 - val_loss: 0.4195 - val_accuracy: 0.8117\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7988 - val_loss: 0.4194 - val_accuracy: 0.8109\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8005 - val_loss: 0.4192 - val_accuracy: 0.8109\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8018 - val_loss: 0.4189 - val_accuracy: 0.8117\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8005 - val_loss: 0.4188 - val_accuracy: 0.8117\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8009 - val_loss: 0.4187 - val_accuracy: 0.8124\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8037 - val_loss: 0.4185 - val_accuracy: 0.8102\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8011 - val_loss: 0.4184 - val_accuracy: 0.8117\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8012 - val_loss: 0.4186 - val_accuracy: 0.8109\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8012 - val_loss: 0.4185 - val_accuracy: 0.8095\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8014 - val_loss: 0.4182 - val_accuracy: 0.8124\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8020 - val_loss: 0.4182 - val_accuracy: 0.8117\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8014 - val_loss: 0.4181 - val_accuracy: 0.8131\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8025 - val_loss: 0.4178 - val_accuracy: 0.8124\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.8016 - val_loss: 0.4181 - val_accuracy: 0.8102\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8030 - val_loss: 0.4178 - val_accuracy: 0.8109\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8018 - val_loss: 0.4177 - val_accuracy: 0.8117\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8014 - val_loss: 0.4176 - val_accuracy: 0.8117\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8034 - val_loss: 0.4176 - val_accuracy: 0.8109\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8023 - val_loss: 0.4174 - val_accuracy: 0.8117\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8039 - val_loss: 0.4172 - val_accuracy: 0.8095\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8034 - val_loss: 0.4174 - val_accuracy: 0.8109\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8034 - val_loss: 0.4168 - val_accuracy: 0.8095\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8044 - val_loss: 0.4169 - val_accuracy: 0.8102\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8023 - val_loss: 0.4168 - val_accuracy: 0.8102\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8043 - val_loss: 0.4170 - val_accuracy: 0.8088\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8039 - val_loss: 0.4168 - val_accuracy: 0.8102\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8037 - val_loss: 0.4168 - val_accuracy: 0.8109\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8037 - val_loss: 0.4164 - val_accuracy: 0.8102\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8039 - val_loss: 0.4166 - val_accuracy: 0.8088\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8055 - val_loss: 0.4166 - val_accuracy: 0.8088\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8052 - val_loss: 0.4164 - val_accuracy: 0.8081\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8053 - val_loss: 0.4162 - val_accuracy: 0.8081\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8048 - val_loss: 0.4169 - val_accuracy: 0.8067\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8048 - val_loss: 0.4158 - val_accuracy: 0.8081\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8059 - val_loss: 0.4162 - val_accuracy: 0.8095\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8060 - val_loss: 0.4159 - val_accuracy: 0.8081\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8060 - val_loss: 0.4156 - val_accuracy: 0.8088\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8059 - val_loss: 0.4156 - val_accuracy: 0.8081\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8078 - val_loss: 0.4161 - val_accuracy: 0.8067\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8064 - val_loss: 0.4154 - val_accuracy: 0.8088\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.8076 - val_loss: 0.4150 - val_accuracy: 0.8088\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8087 - val_loss: 0.4153 - val_accuracy: 0.8088\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8068 - val_loss: 0.4156 - val_accuracy: 0.8074\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8071 - val_loss: 0.4150 - val_accuracy: 0.8045\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8094 - val_loss: 0.4153 - val_accuracy: 0.8074\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8080 - val_loss: 0.4152 - val_accuracy: 0.8081\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8091 - val_loss: 0.4149 - val_accuracy: 0.8045\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8094 - val_loss: 0.4150 - val_accuracy: 0.8088\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8080 - val_loss: 0.4149 - val_accuracy: 0.8088\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8110 - val_loss: 0.4157 - val_accuracy: 0.8060\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8100 - val_loss: 0.4148 - val_accuracy: 0.8074\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8087 - val_loss: 0.4146 - val_accuracy: 0.8074\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8110 - val_loss: 0.4147 - val_accuracy: 0.8060\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8112 - val_loss: 0.4149 - val_accuracy: 0.8081\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8112 - val_loss: 0.4149 - val_accuracy: 0.8074\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8101 - val_loss: 0.4148 - val_accuracy: 0.8081\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8114 - val_loss: 0.4157 - val_accuracy: 0.8053\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8100 - val_loss: 0.4149 - val_accuracy: 0.8060\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8124 - val_loss: 0.4152 - val_accuracy: 0.8045\n",
      "44/44 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, weights=None):\n",
    "    size = X_train.shape[1]\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(size, activation=\"relu\"),\n",
    "        Dense(units=1,activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=100,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          batch_size=256,\n",
    "          class_weight=weights)\n",
    "    \n",
    "    predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "predictions = ANN(X_train, y_train, X_test, y_test, weights=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model Performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      1052\n",
      "           1       0.63      0.53      0.58       355\n",
      "\n",
      "    accuracy                           0.80      1407\n",
      "   macro avg       0.74      0.71      0.73      1407\n",
      "weighted avg       0.80      0.80      0.80      1407\n",
      "\n",
      "[[943 109]\n",
      " [166 189]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, it can be noticed that the class 1 has a low F1 score, suggesting an unbalnaced dataset! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitigating Skewdness of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Adjusting the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 5163\n",
      "Class 1: 1869\n",
      "Ratio: 2.7624398073836276\n"
     ]
    }
   ],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = df1.Churn.value_counts()\n",
    "\n",
    "print(f\"\"\"Class 0: {count_class_0}\n",
    "Class 1: {count_class_1}\n",
    "Ratio: {count_class_0/count_class_1}\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticing there is a ratio of 1:2.8 between 0:1, the weights will get adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 1s 15ms/step - loss: 1.0667 - accuracy: 0.5445 - val_loss: 0.6485 - val_accuracy: 0.6304\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.9711 - accuracy: 0.6428 - val_loss: 0.6015 - val_accuracy: 0.7029\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8993 - accuracy: 0.6958 - val_loss: 0.5737 - val_accuracy: 0.7271\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8440 - accuracy: 0.7223 - val_loss: 0.5427 - val_accuracy: 0.7356\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.8067 - accuracy: 0.7383 - val_loss: 0.5307 - val_accuracy: 0.7392\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7817 - accuracy: 0.7488 - val_loss: 0.5148 - val_accuracy: 0.7477\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7655 - accuracy: 0.7467 - val_loss: 0.5185 - val_accuracy: 0.7420\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7541 - accuracy: 0.7502 - val_loss: 0.5064 - val_accuracy: 0.7477\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7454 - accuracy: 0.7486 - val_loss: 0.5021 - val_accuracy: 0.7534\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7395 - accuracy: 0.7552 - val_loss: 0.5086 - val_accuracy: 0.7463\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.7486 - val_loss: 0.4953 - val_accuracy: 0.7548\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7298 - accuracy: 0.7572 - val_loss: 0.5037 - val_accuracy: 0.7477\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7267 - accuracy: 0.7513 - val_loss: 0.5000 - val_accuracy: 0.7520\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7249 - accuracy: 0.7582 - val_loss: 0.5019 - val_accuracy: 0.7512\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7227 - accuracy: 0.7477 - val_loss: 0.4961 - val_accuracy: 0.7505\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7216 - accuracy: 0.7557 - val_loss: 0.5034 - val_accuracy: 0.7477\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7198 - accuracy: 0.7481 - val_loss: 0.4918 - val_accuracy: 0.7527\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7191 - accuracy: 0.7504 - val_loss: 0.4905 - val_accuracy: 0.7534\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7173 - accuracy: 0.7559 - val_loss: 0.4974 - val_accuracy: 0.7491\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7177 - accuracy: 0.7463 - val_loss: 0.4862 - val_accuracy: 0.7534\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7159 - accuracy: 0.7547 - val_loss: 0.4985 - val_accuracy: 0.7498\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7150 - accuracy: 0.7472 - val_loss: 0.4988 - val_accuracy: 0.7505\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7141 - accuracy: 0.7532 - val_loss: 0.4913 - val_accuracy: 0.7505\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7141 - accuracy: 0.7495 - val_loss: 0.4928 - val_accuracy: 0.7512\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7130 - accuracy: 0.7520 - val_loss: 0.5000 - val_accuracy: 0.7505\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7138 - accuracy: 0.7445 - val_loss: 0.4850 - val_accuracy: 0.7555\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7124 - accuracy: 0.7534 - val_loss: 0.4991 - val_accuracy: 0.7484\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7117 - accuracy: 0.7509 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7111 - accuracy: 0.7483 - val_loss: 0.4932 - val_accuracy: 0.7498\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.7108 - accuracy: 0.7500 - val_loss: 0.4950 - val_accuracy: 0.7498\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7104 - accuracy: 0.7561 - val_loss: 0.5015 - val_accuracy: 0.7463\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7100 - accuracy: 0.7460 - val_loss: 0.4977 - val_accuracy: 0.7484\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7090 - accuracy: 0.7515 - val_loss: 0.4929 - val_accuracy: 0.7498\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7089 - accuracy: 0.7515 - val_loss: 0.4962 - val_accuracy: 0.7463\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7088 - accuracy: 0.7541 - val_loss: 0.4927 - val_accuracy: 0.7484\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7086 - accuracy: 0.7506 - val_loss: 0.4927 - val_accuracy: 0.7491\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7075 - accuracy: 0.7524 - val_loss: 0.4950 - val_accuracy: 0.7491\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7072 - accuracy: 0.7547 - val_loss: 0.5005 - val_accuracy: 0.7448\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7075 - accuracy: 0.7524 - val_loss: 0.4975 - val_accuracy: 0.7498\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7069 - accuracy: 0.7504 - val_loss: 0.4932 - val_accuracy: 0.7498\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7061 - accuracy: 0.7524 - val_loss: 0.4940 - val_accuracy: 0.7484\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7068 - accuracy: 0.7518 - val_loss: 0.4875 - val_accuracy: 0.7520\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7052 - accuracy: 0.7541 - val_loss: 0.5072 - val_accuracy: 0.7370\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7056 - accuracy: 0.7484 - val_loss: 0.4892 - val_accuracy: 0.7505\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7050 - accuracy: 0.7604 - val_loss: 0.5104 - val_accuracy: 0.7292\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7057 - accuracy: 0.7465 - val_loss: 0.4936 - val_accuracy: 0.7512\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.7038 - accuracy: 0.7531 - val_loss: 0.4929 - val_accuracy: 0.7491\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7036 - accuracy: 0.7582 - val_loss: 0.4989 - val_accuracy: 0.7456\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7034 - accuracy: 0.7518 - val_loss: 0.4928 - val_accuracy: 0.7498\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.7545 - val_loss: 0.5001 - val_accuracy: 0.7448\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7035 - accuracy: 0.7541 - val_loss: 0.4998 - val_accuracy: 0.7463\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7024 - accuracy: 0.7563 - val_loss: 0.4947 - val_accuracy: 0.7463\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7025 - accuracy: 0.7518 - val_loss: 0.4879 - val_accuracy: 0.7520\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.7550 - val_loss: 0.4951 - val_accuracy: 0.7463\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7014 - accuracy: 0.7566 - val_loss: 0.4994 - val_accuracy: 0.7463\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7014 - accuracy: 0.7534 - val_loss: 0.4881 - val_accuracy: 0.7505\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7007 - accuracy: 0.7548 - val_loss: 0.5034 - val_accuracy: 0.7399\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.7005 - accuracy: 0.7573 - val_loss: 0.4996 - val_accuracy: 0.7441\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.7529 - val_loss: 0.4937 - val_accuracy: 0.7491\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6997 - accuracy: 0.7541 - val_loss: 0.4957 - val_accuracy: 0.7477\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6993 - accuracy: 0.7536 - val_loss: 0.4927 - val_accuracy: 0.7498\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6995 - accuracy: 0.7556 - val_loss: 0.5072 - val_accuracy: 0.7321\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.7524 - val_loss: 0.4924 - val_accuracy: 0.7498\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6985 - accuracy: 0.7573 - val_loss: 0.4956 - val_accuracy: 0.7484\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6984 - accuracy: 0.7532 - val_loss: 0.4919 - val_accuracy: 0.7491\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6986 - accuracy: 0.7540 - val_loss: 0.4862 - val_accuracy: 0.7548\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6974 - accuracy: 0.7552 - val_loss: 0.4955 - val_accuracy: 0.7477\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6977 - accuracy: 0.7536 - val_loss: 0.5061 - val_accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.7547 - val_loss: 0.4878 - val_accuracy: 0.7520\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.7584 - val_loss: 0.5059 - val_accuracy: 0.7349\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6983 - accuracy: 0.7561 - val_loss: 0.4868 - val_accuracy: 0.7548\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.7508 - val_loss: 0.5045 - val_accuracy: 0.7342\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.7591 - val_loss: 0.4998 - val_accuracy: 0.7420\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.7518 - val_loss: 0.4891 - val_accuracy: 0.7520\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.7559 - val_loss: 0.5019 - val_accuracy: 0.7392\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.6965 - accuracy: 0.7570 - val_loss: 0.5062 - val_accuracy: 0.7377\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.7563 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.7509 - val_loss: 0.4877 - val_accuracy: 0.7541\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.7582 - val_loss: 0.5031 - val_accuracy: 0.7385\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.7529 - val_loss: 0.4960 - val_accuracy: 0.7434\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.7593 - val_loss: 0.5068 - val_accuracy: 0.7328\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6938 - accuracy: 0.7534 - val_loss: 0.4935 - val_accuracy: 0.7477\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.7575 - val_loss: 0.4989 - val_accuracy: 0.7420\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.7579 - val_loss: 0.4994 - val_accuracy: 0.7399\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.7547 - val_loss: 0.4927 - val_accuracy: 0.7498\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.7575 - val_loss: 0.4981 - val_accuracy: 0.7427\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6927 - accuracy: 0.7568 - val_loss: 0.4912 - val_accuracy: 0.7498\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6922 - accuracy: 0.7579 - val_loss: 0.4986 - val_accuracy: 0.7413\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.7563 - val_loss: 0.4931 - val_accuracy: 0.7477\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6917 - accuracy: 0.7577 - val_loss: 0.4967 - val_accuracy: 0.7434\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.7559 - val_loss: 0.5025 - val_accuracy: 0.7370\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6915 - accuracy: 0.7573 - val_loss: 0.4974 - val_accuracy: 0.7413\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6912 - accuracy: 0.7561 - val_loss: 0.4892 - val_accuracy: 0.7527\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.7598 - val_loss: 0.5014 - val_accuracy: 0.7370\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.7493 - val_loss: 0.4763 - val_accuracy: 0.7576\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.7616 - val_loss: 0.5150 - val_accuracy: 0.7257\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.6907 - accuracy: 0.7532 - val_loss: 0.4889 - val_accuracy: 0.7534\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6899 - accuracy: 0.7572 - val_loss: 0.4965 - val_accuracy: 0.7427\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.6900 - accuracy: 0.7580 - val_loss: 0.4908 - val_accuracy: 0.7512\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.7561 - val_loss: 0.4916 - val_accuracy: 0.7491\n",
      "44/44 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = ANN(X_train, y_train, X_test, y_test, weights={0: 1, 1: 2.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.82      1052\n",
      "           1       0.50      0.77      0.61       355\n",
      "\n",
      "    accuracy                           0.75      1407\n",
      "   macro avg       0.70      0.75      0.71      1407\n",
      "weighted avg       0.80      0.75      0.76      1407\n",
      "\n",
      "[[782 270]\n",
      " [ 83 272]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result it can be noticed that in the confusion matrix less values are misplaced for class 1 and more values are misplaced for class 0, showing a trade off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Undersampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.90</td>\n",
       "      <td>1356.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.70</td>\n",
       "      <td>168.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>100.45</td>\n",
       "      <td>3414.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>80.80</td>\n",
       "      <td>4860.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.15</td>\n",
       "      <td>2215.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.80</td>\n",
       "      <td>727.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.20</td>\n",
       "      <td>403.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.75</td>\n",
       "      <td>75.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7034</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>102.95</td>\n",
       "      <td>6886.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3738 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "3707       1              0        1           1      69             1   \n",
       "2352       1              0        0           0       8             1   \n",
       "4745       0              0        1           0      34             1   \n",
       "6208       1              0        1           0      61             1   \n",
       "86         0              0        1           0      35             1   \n",
       "...      ...            ...      ...         ...     ...           ...   \n",
       "7021       1              0        0           0      12             1   \n",
       "7026       0              0        0           0       9             1   \n",
       "7032       1              1        0           0       1             1   \n",
       "7034       0              0        0           0      67             1   \n",
       "7041       1              1        1           0       4             1   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  ...  \\\n",
       "3707              0               0             0                 0  ...   \n",
       "2352              0               0             0                 0  ...   \n",
       "4745              1               0             0                 1  ...   \n",
       "6208              1               1             1                 1  ...   \n",
       "86                0               1             0                 0  ...   \n",
       "...             ...             ...           ...               ...  ...   \n",
       "7021              0               0             0                 0  ...   \n",
       "7026              0               0             0                 0  ...   \n",
       "7032              1               0             0                 0  ...   \n",
       "7034              1               1             1                 1  ...   \n",
       "7041              1               0             0                 0  ...   \n",
       "\n",
       "      MonthlyCharges  TotalCharges  Churn  InternetService_Fiber optic  \\\n",
       "3707           19.90       1356.70      0                            0   \n",
       "2352           19.70        168.90      0                            0   \n",
       "4745          100.45       3414.65      0                            1   \n",
       "6208           80.80       4860.85      0                            0   \n",
       "86             62.15       2215.45      0                            0   \n",
       "...              ...           ...    ...                          ...   \n",
       "7021           59.80        727.80      1                            0   \n",
       "7026           44.20        403.35      1                            0   \n",
       "7032           75.75         75.75      1                            1   \n",
       "7034          102.95       6886.25      1                            1   \n",
       "7041           74.40        306.60      1                            1   \n",
       "\n",
       "      InternetService_No  Contract_One year  Contract_Two year  \\\n",
       "3707                   1                  0                  1   \n",
       "2352                   1                  0                  0   \n",
       "4745                   0                  0                  0   \n",
       "6208                   0                  0                  1   \n",
       "86                     0                  1                  0   \n",
       "...                  ...                ...                ...   \n",
       "7021                   0                  1                  0   \n",
       "7026                   0                  0                  0   \n",
       "7032                   0                  0                  0   \n",
       "7034                   0                  0                  0   \n",
       "7041                   0                  0                  0   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "3707                                      0                               0   \n",
       "2352                                      0                               0   \n",
       "4745                                      0                               1   \n",
       "6208                                      0                               0   \n",
       "86                                        0                               0   \n",
       "...                                     ...                             ...   \n",
       "7021                                      0                               1   \n",
       "7026                                      0                               0   \n",
       "7032                                      0                               1   \n",
       "7034                                      1                               0   \n",
       "7041                                      0                               0   \n",
       "\n",
       "      PaymentMethod_Mailed check  \n",
       "3707                           0  \n",
       "2352                           0  \n",
       "4745                           0  \n",
       "6208                           0  \n",
       "86                             0  \n",
       "...                          ...  \n",
       "7021                           0  \n",
       "7026                           0  \n",
       "7032                           0  \n",
       "7034                           0  \n",
       "7041                           1  \n",
       "\n",
       "[3738 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide by class\n",
    "df_class_0 = df1[df1['Churn'] == 0]\n",
    "df_class_1 = df1[df1['Churn'] == 1]\n",
    "\n",
    "\n",
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "df_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "0    1869\n",
      "1    1869\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Random under-sampling:')\n",
    "print(df_under.Churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_under.drop('Churn',axis='columns')\n",
    "y = df_under['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 251.6011 - accuracy: 0.5000 - val_loss: 186.7665 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 162.5669 - accuracy: 0.5000 - val_loss: 103.4698 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 72.4408 - accuracy: 0.4716 - val_loss: 22.3601 - val_accuracy: 0.3342\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 15.1707 - accuracy: 0.4331 - val_loss: 20.4504 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 15.5752 - accuracy: 0.5003 - val_loss: 4.7525 - val_accuracy: 0.5428\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.2741 - accuracy: 0.4538 - val_loss: 3.0658 - val_accuracy: 0.5949\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.4126 - accuracy: 0.5977 - val_loss: 1.5490 - val_accuracy: 0.6751\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 1.2197 - accuracy: 0.6595 - val_loss: 0.8506 - val_accuracy: 0.6925\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.7707 - accuracy: 0.6823 - val_loss: 0.6357 - val_accuracy: 0.7032\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.7010 - val_loss: 0.6250 - val_accuracy: 0.6805\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.7094 - val_loss: 0.6098 - val_accuracy: 0.6725\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5748 - accuracy: 0.7117 - val_loss: 0.5586 - val_accuracy: 0.6939\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5611 - accuracy: 0.7191 - val_loss: 0.5574 - val_accuracy: 0.7086\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5488 - accuracy: 0.7194 - val_loss: 0.6289 - val_accuracy: 0.6939\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5669 - accuracy: 0.7164 - val_loss: 0.5563 - val_accuracy: 0.7166\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5494 - accuracy: 0.7184 - val_loss: 0.6117 - val_accuracy: 0.6845\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5966 - accuracy: 0.7094 - val_loss: 0.5436 - val_accuracy: 0.7152\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.7301 - val_loss: 0.6098 - val_accuracy: 0.7019\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.7411 - val_loss: 0.5424 - val_accuracy: 0.7273\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5529 - accuracy: 0.7291 - val_loss: 0.6756 - val_accuracy: 0.6965\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5545 - accuracy: 0.7251 - val_loss: 0.5485 - val_accuracy: 0.7045\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7324 - val_loss: 0.5437 - val_accuracy: 0.7313\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.7448 - val_loss: 0.5303 - val_accuracy: 0.7313\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5234 - accuracy: 0.7391 - val_loss: 0.5294 - val_accuracy: 0.7273\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.7428 - val_loss: 0.5275 - val_accuracy: 0.7286\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7498 - val_loss: 0.5308 - val_accuracy: 0.7246\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.5341 - accuracy: 0.7385 - val_loss: 0.5408 - val_accuracy: 0.7259\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7401 - val_loss: 0.5517 - val_accuracy: 0.7246\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5280 - accuracy: 0.7425 - val_loss: 0.5235 - val_accuracy: 0.7273\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5071 - accuracy: 0.7518 - val_loss: 0.5600 - val_accuracy: 0.7005\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7421 - val_loss: 0.5276 - val_accuracy: 0.7259\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5247 - accuracy: 0.7428 - val_loss: 0.5493 - val_accuracy: 0.7299\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7401 - val_loss: 0.6323 - val_accuracy: 0.7126\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7331 - val_loss: 0.5539 - val_accuracy: 0.7259\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5491 - accuracy: 0.7358 - val_loss: 0.6322 - val_accuracy: 0.7219\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7431 - val_loss: 0.5202 - val_accuracy: 0.7246\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.7492 - val_loss: 0.5200 - val_accuracy: 0.7273\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7452 - val_loss: 0.5157 - val_accuracy: 0.7380\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7492 - val_loss: 0.5685 - val_accuracy: 0.6992\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7378 - val_loss: 0.5561 - val_accuracy: 0.7032\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7498 - val_loss: 0.5172 - val_accuracy: 0.7286\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5042 - accuracy: 0.7502 - val_loss: 0.6153 - val_accuracy: 0.6872\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5895 - accuracy: 0.7304 - val_loss: 0.5254 - val_accuracy: 0.7233\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7435 - val_loss: 0.7051 - val_accuracy: 0.7126\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5546 - accuracy: 0.7378 - val_loss: 0.5372 - val_accuracy: 0.7313\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5648 - accuracy: 0.7365 - val_loss: 0.5134 - val_accuracy: 0.7366\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7465 - val_loss: 0.5133 - val_accuracy: 0.7393\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7575 - val_loss: 0.5426 - val_accuracy: 0.7326\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.7545 - val_loss: 0.5320 - val_accuracy: 0.7353\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7525 - val_loss: 0.5462 - val_accuracy: 0.7313\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7522 - val_loss: 0.5505 - val_accuracy: 0.7313\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7462 - val_loss: 0.5199 - val_accuracy: 0.7286\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7579 - val_loss: 0.5339 - val_accuracy: 0.7353\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.7435 - val_loss: 0.7496 - val_accuracy: 0.7032\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5580 - accuracy: 0.7411 - val_loss: 0.5416 - val_accuracy: 0.7353\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7472 - val_loss: 0.5398 - val_accuracy: 0.7326\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7455 - val_loss: 0.5090 - val_accuracy: 0.7420\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5715 - accuracy: 0.7455 - val_loss: 0.8072 - val_accuracy: 0.7005\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6497 - accuracy: 0.7201 - val_loss: 0.6384 - val_accuracy: 0.6872\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7770 - accuracy: 0.7040 - val_loss: 0.7845 - val_accuracy: 0.7086\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6596 - accuracy: 0.7258 - val_loss: 0.6711 - val_accuracy: 0.6898\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7750 - accuracy: 0.7094 - val_loss: 0.5512 - val_accuracy: 0.7326\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7448 - val_loss: 0.5525 - val_accuracy: 0.7086\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7562 - val_loss: 0.5092 - val_accuracy: 0.7420\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4923 - accuracy: 0.7615 - val_loss: 0.5079 - val_accuracy: 0.7393\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4949 - accuracy: 0.7592 - val_loss: 0.5085 - val_accuracy: 0.7393\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5099 - accuracy: 0.7528 - val_loss: 0.8440 - val_accuracy: 0.6604\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.7011 - accuracy: 0.7120 - val_loss: 0.6666 - val_accuracy: 0.7259\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6246 - accuracy: 0.7244 - val_loss: 0.6573 - val_accuracy: 0.6912\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5818 - accuracy: 0.7355 - val_loss: 0.5209 - val_accuracy: 0.7299\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7642 - val_loss: 0.5118 - val_accuracy: 0.7366\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7579 - val_loss: 0.5080 - val_accuracy: 0.7393\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5174 - accuracy: 0.7528 - val_loss: 0.5070 - val_accuracy: 0.7487\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5595 - accuracy: 0.7348 - val_loss: 0.5349 - val_accuracy: 0.7366\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.7478 - val_loss: 0.7276 - val_accuracy: 0.7139\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5668 - accuracy: 0.7405 - val_loss: 0.6434 - val_accuracy: 0.7246\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7438 - val_loss: 0.6486 - val_accuracy: 0.7246\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5266 - accuracy: 0.7548 - val_loss: 0.5669 - val_accuracy: 0.7273\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5485 - accuracy: 0.7431 - val_loss: 0.5988 - val_accuracy: 0.6925\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5169 - accuracy: 0.7515 - val_loss: 0.5223 - val_accuracy: 0.7273\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7522 - val_loss: 0.5057 - val_accuracy: 0.7460\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7528 - val_loss: 0.5340 - val_accuracy: 0.7206\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5302 - accuracy: 0.7462 - val_loss: 0.5643 - val_accuracy: 0.7259\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.7498 - val_loss: 0.5158 - val_accuracy: 0.7353\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.7592 - val_loss: 0.6385 - val_accuracy: 0.7259\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6112 - accuracy: 0.7261 - val_loss: 0.5504 - val_accuracy: 0.7353\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.7425 - val_loss: 0.5070 - val_accuracy: 0.7433\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.6303 - accuracy: 0.7291 - val_loss: 0.5085 - val_accuracy: 0.7460\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6543 - accuracy: 0.7181 - val_loss: 0.5272 - val_accuracy: 0.7366\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.7441 - val_loss: 0.5747 - val_accuracy: 0.7259\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5191 - accuracy: 0.7559 - val_loss: 0.5171 - val_accuracy: 0.7299\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7642 - val_loss: 0.5044 - val_accuracy: 0.7460\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7562 - val_loss: 0.5719 - val_accuracy: 0.7299\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7498 - val_loss: 0.5132 - val_accuracy: 0.7393\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.7579 - val_loss: 0.5340 - val_accuracy: 0.7380\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5215 - accuracy: 0.7495 - val_loss: 0.6267 - val_accuracy: 0.7286\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.6095 - accuracy: 0.7271 - val_loss: 0.5905 - val_accuracy: 0.7313\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.5083 - accuracy: 0.7599 - val_loss: 0.5074 - val_accuracy: 0.7340\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7629 - val_loss: 0.5604 - val_accuracy: 0.7299\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.7555 - val_loss: 0.5417 - val_accuracy: 0.7353\n",
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = ANN(X_train, y_train, X_test, y_test, weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.82      0.75       374\n",
      "           1       0.78      0.66      0.71       374\n",
      "\n",
      "    accuracy                           0.74       748\n",
      "   macro avg       0.74      0.74      0.73       748\n",
      "weighted avg       0.74      0.74      0.73       748\n",
      "\n",
      "[[305  69]\n",
      " [129 245]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear trade off in the F1 scores, improving the one of class 1 and reducing the one of class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>...</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>InternetService_No</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.10</td>\n",
       "      <td>1949.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.75</td>\n",
       "      <td>301.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>94.25</td>\n",
       "      <td>3217.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.15</td>\n",
       "      <td>2995.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.35</td>\n",
       "      <td>3515.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99.50</td>\n",
       "      <td>5961.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.15</td>\n",
       "      <td>987.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10326 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "0          0              0        1           0       1             0   \n",
       "1          1              0        0           0      34             1   \n",
       "3          1              0        0           0      45             0   \n",
       "6          1              0        0           1      22             1   \n",
       "7          0              0        0           0      10             0   \n",
       "...      ...            ...      ...         ...     ...           ...   \n",
       "1389       0              1        1           0      34             1   \n",
       "4856       0              0        1           1      31             1   \n",
       "4149       1              0        1           0      71             0   \n",
       "1327       1              0        1           0      59             1   \n",
       "1248       0              0        0           0      11             1   \n",
       "\n",
       "      MultipleLines  OnlineSecurity  OnlineBackup  DeviceProtection  ...  \\\n",
       "0                 0               0             1                 0  ...   \n",
       "1                 0               1             0                 1  ...   \n",
       "3                 0               1             0                 1  ...   \n",
       "6                 1               0             1                 0  ...   \n",
       "7                 0               1             0                 0  ...   \n",
       "...             ...             ...           ...               ...  ...   \n",
       "1389              1               0             1                 1  ...   \n",
       "4856              1               0             1                 0  ...   \n",
       "4149              0               0             1                 0  ...   \n",
       "1327              1               0             0                 1  ...   \n",
       "1248              1               0             0                 0  ...   \n",
       "\n",
       "      MonthlyCharges  TotalCharges  Churn  InternetService_Fiber optic  \\\n",
       "0              29.85         29.85      0                            0   \n",
       "1              56.95       1889.50      0                            0   \n",
       "3              42.30       1840.75      0                            0   \n",
       "6              89.10       1949.40      0                            1   \n",
       "7              29.75        301.90      0                            0   \n",
       "...              ...           ...    ...                          ...   \n",
       "1389           94.25       3217.55      1                            1   \n",
       "4856           91.15       2995.45      1                            1   \n",
       "4149           49.35       3515.25      1                            0   \n",
       "1327           99.50       5961.10      1                            1   \n",
       "1248           90.15        987.95      1                            1   \n",
       "\n",
       "      InternetService_No  Contract_One year  Contract_Two year  \\\n",
       "0                      0                  0                  0   \n",
       "1                      0                  1                  0   \n",
       "3                      0                  1                  0   \n",
       "6                      0                  0                  0   \n",
       "7                      0                  0                  0   \n",
       "...                  ...                ...                ...   \n",
       "1389                   0                  0                  0   \n",
       "4856                   0                  0                  0   \n",
       "4149                   0                  0                  1   \n",
       "1327                   0                  1                  0   \n",
       "1248                   0                  0                  0   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                         0                               1   \n",
       "1                                         0                               0   \n",
       "3                                         0                               0   \n",
       "6                                         1                               0   \n",
       "7                                         0                               0   \n",
       "...                                     ...                             ...   \n",
       "1389                                      0                               1   \n",
       "4856                                      0                               1   \n",
       "4149                                      0                               1   \n",
       "1327                                      0                               0   \n",
       "1248                                      0                               1   \n",
       "\n",
       "      PaymentMethod_Mailed check  \n",
       "0                              0  \n",
       "1                              1  \n",
       "3                              0  \n",
       "6                              0  \n",
       "7                              1  \n",
       "...                          ...  \n",
       "1389                           0  \n",
       "4856                           0  \n",
       "4149                           0  \n",
       "1327                           0  \n",
       "1248                           0  \n",
       "\n",
       "[10326 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide by class\n",
    "df_class_0 = df1[df1['Churn'] == 0]\n",
    "df_class_1 = df1[df1['Churn'] == 1]\n",
    "\n",
    "\n",
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "df_class_1_up = df_class_1.sample(count_class_0, replace=True)\n",
    "df_up = pd.concat([df_class_0, df_class_1_up], axis=0)\n",
    "df_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "0    5163\n",
      "1    5163\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Random over-sampling:')\n",
    "print(df_up.Churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_up.drop('Churn',axis='columns')\n",
    "y = df_up['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 355.4727 - accuracy: 0.5000 - val_loss: 290.8560 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 229.0171 - accuracy: 0.4703 - val_loss: 174.9963 - val_accuracy: 0.4652\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 122.6245 - accuracy: 0.4192 - val_loss: 72.7396 - val_accuracy: 0.4356\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 31.4720 - accuracy: 0.4431 - val_loss: 1.7695 - val_accuracy: 0.6012\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.8904 - accuracy: 0.6067 - val_loss: 0.6989 - val_accuracy: 0.6970\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6930 - val_loss: 0.5901 - val_accuracy: 0.7183\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5814 - accuracy: 0.7301 - val_loss: 0.5550 - val_accuracy: 0.7391\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5649 - accuracy: 0.7380 - val_loss: 0.5435 - val_accuracy: 0.7435\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5592 - accuracy: 0.7395 - val_loss: 0.5761 - val_accuracy: 0.7018\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5540 - accuracy: 0.7374 - val_loss: 0.5550 - val_accuracy: 0.7207\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.7223 - val_loss: 0.5858 - val_accuracy: 0.6946\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7487 - val_loss: 0.5243 - val_accuracy: 0.7541\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7499 - val_loss: 0.5213 - val_accuracy: 0.7609\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7506 - val_loss: 0.6003 - val_accuracy: 0.7338\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5380 - accuracy: 0.7495 - val_loss: 0.5314 - val_accuracy: 0.7435\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7563 - val_loss: 0.5357 - val_accuracy: 0.7362\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7502 - val_loss: 0.5137 - val_accuracy: 0.7638\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7545 - val_loss: 0.5140 - val_accuracy: 0.7662\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7524 - val_loss: 0.5107 - val_accuracy: 0.7609\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5208 - accuracy: 0.7498 - val_loss: 0.4938 - val_accuracy: 0.7531\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5200 - accuracy: 0.7427 - val_loss: 0.4944 - val_accuracy: 0.7507\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.7500 - val_loss: 0.5026 - val_accuracy: 0.7498\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.7482 - val_loss: 0.4916 - val_accuracy: 0.7536\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.7504 - val_loss: 0.4906 - val_accuracy: 0.7541\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7513 - val_loss: 0.5038 - val_accuracy: 0.7420\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7539 - val_loss: 0.5029 - val_accuracy: 0.7536\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4927 - accuracy: 0.7550 - val_loss: 0.4892 - val_accuracy: 0.7619\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7581 - val_loss: 0.4867 - val_accuracy: 0.7652\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7529 - val_loss: 0.5055 - val_accuracy: 0.7556\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7539 - val_loss: 0.4859 - val_accuracy: 0.7667\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7484 - val_loss: 0.5277 - val_accuracy: 0.7531\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5199 - accuracy: 0.7459 - val_loss: 0.4866 - val_accuracy: 0.7643\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7539 - val_loss: 0.5143 - val_accuracy: 0.7377\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5178 - accuracy: 0.7459 - val_loss: 0.4884 - val_accuracy: 0.7643\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7525 - val_loss: 0.5166 - val_accuracy: 0.7609\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7548 - val_loss: 0.5050 - val_accuracy: 0.7648\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7582 - val_loss: 0.5024 - val_accuracy: 0.7546\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.7598 - val_loss: 0.4901 - val_accuracy: 0.7662\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7562 - val_loss: 0.5356 - val_accuracy: 0.7570\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7553 - val_loss: 0.4861 - val_accuracy: 0.7662\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7598 - val_loss: 0.6053 - val_accuracy: 0.7052\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.7557 - val_loss: 0.5222 - val_accuracy: 0.7343\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7489 - val_loss: 0.4887 - val_accuracy: 0.7662\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7639 - val_loss: 0.5155 - val_accuracy: 0.7420\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7621 - val_loss: 0.5702 - val_accuracy: 0.7173\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7587 - val_loss: 0.4814 - val_accuracy: 0.7744\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7567 - val_loss: 0.4901 - val_accuracy: 0.7686\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7642 - val_loss: 0.6436 - val_accuracy: 0.6902\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7511 - val_loss: 0.5286 - val_accuracy: 0.7338\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7638 - val_loss: 0.5128 - val_accuracy: 0.7493\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7626 - val_loss: 0.4884 - val_accuracy: 0.7682\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7619 - val_loss: 0.4976 - val_accuracy: 0.7614\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7435 - val_loss: 0.6087 - val_accuracy: 0.7043\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7431 - val_loss: 0.5615 - val_accuracy: 0.7193\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7565 - val_loss: 0.4908 - val_accuracy: 0.7706\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7527 - val_loss: 0.5343 - val_accuracy: 0.7352\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7545 - val_loss: 0.4969 - val_accuracy: 0.7672\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7573 - val_loss: 0.5165 - val_accuracy: 0.7701\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7622 - val_loss: 0.4940 - val_accuracy: 0.7667\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7613 - val_loss: 0.4835 - val_accuracy: 0.7706\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7637 - val_loss: 0.4793 - val_accuracy: 0.7735\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7639 - val_loss: 0.4985 - val_accuracy: 0.7682\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7602 - val_loss: 0.4922 - val_accuracy: 0.7701\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7638 - val_loss: 0.4824 - val_accuracy: 0.7711\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.7626 - val_loss: 0.5194 - val_accuracy: 0.7686\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7655 - val_loss: 0.4968 - val_accuracy: 0.7667\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7553 - val_loss: 0.5020 - val_accuracy: 0.7585\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7427 - val_loss: 0.5948 - val_accuracy: 0.7096\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7562 - val_loss: 0.4877 - val_accuracy: 0.7696\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7634 - val_loss: 0.4803 - val_accuracy: 0.7740\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7631 - val_loss: 0.4826 - val_accuracy: 0.7706\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7649 - val_loss: 0.4810 - val_accuracy: 0.7764\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7660 - val_loss: 0.6494 - val_accuracy: 0.6941\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7650 - val_loss: 0.4836 - val_accuracy: 0.7706\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7538 - val_loss: 0.6082 - val_accuracy: 0.7473\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7443 - val_loss: 0.5127 - val_accuracy: 0.7667\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7562 - val_loss: 0.5101 - val_accuracy: 0.7677\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7588 - val_loss: 0.4871 - val_accuracy: 0.7706\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7590 - val_loss: 0.4909 - val_accuracy: 0.7711\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7643 - val_loss: 0.5417 - val_accuracy: 0.7609\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7615 - val_loss: 0.4790 - val_accuracy: 0.7754\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7477 - val_loss: 0.4920 - val_accuracy: 0.7696\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7609 - val_loss: 0.4855 - val_accuracy: 0.7740\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7631 - val_loss: 0.5110 - val_accuracy: 0.7541\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7660 - val_loss: 0.5068 - val_accuracy: 0.7575\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7596 - val_loss: 0.4807 - val_accuracy: 0.7759\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7637 - val_loss: 0.4781 - val_accuracy: 0.7744\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7634 - val_loss: 0.5017 - val_accuracy: 0.7609\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7628 - val_loss: 0.4778 - val_accuracy: 0.7735\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7613 - val_loss: 0.4813 - val_accuracy: 0.7696\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7639 - val_loss: 0.5078 - val_accuracy: 0.7551\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7591 - val_loss: 0.5021 - val_accuracy: 0.7599\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7613 - val_loss: 0.4826 - val_accuracy: 0.7701\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7539 - val_loss: 0.5842 - val_accuracy: 0.7154\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7619 - val_loss: 0.4813 - val_accuracy: 0.7773\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7686 - val_loss: 0.4781 - val_accuracy: 0.7725\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7620 - val_loss: 0.4779 - val_accuracy: 0.7744\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7633 - val_loss: 0.5355 - val_accuracy: 0.7372\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7619 - val_loss: 0.5333 - val_accuracy: 0.7362\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.7610 - val_loss: 0.4931 - val_accuracy: 0.7706\n",
      "65/65 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = ANN(X_train, y_train, X_test, y_test, weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      1033\n",
      "           1       0.79      0.74      0.76      1033\n",
      "\n",
      "    accuracy                           0.77      2066\n",
      "   macro avg       0.77      0.77      0.77      2066\n",
      "weighted avg       0.77      0.77      0.77      2066\n",
      "\n",
      "[[826 207]\n",
      " [267 766]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5163\n",
       "1    5163\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X,y)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 1s 12ms/step - loss: 94.7653 - accuracy: 0.5189 - val_loss: 14.1437 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 6.2150 - accuracy: 0.5872 - val_loss: 2.8729 - val_accuracy: 0.4913\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.9234 - accuracy: 0.5835 - val_loss: 1.3295 - val_accuracy: 0.5169\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.0726 - accuracy: 0.6059 - val_loss: 1.0006 - val_accuracy: 0.6694\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.7324 - accuracy: 0.6746 - val_loss: 0.7558 - val_accuracy: 0.6791\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6806 - accuracy: 0.6812 - val_loss: 0.5181 - val_accuracy: 0.7314\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5623 - accuracy: 0.7223 - val_loss: 0.5091 - val_accuracy: 0.7420\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7369 - val_loss: 0.5020 - val_accuracy: 0.7333\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5741 - accuracy: 0.7247 - val_loss: 0.5101 - val_accuracy: 0.7425\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7360 - val_loss: 0.9593 - val_accuracy: 0.6167\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.7055 - accuracy: 0.7027 - val_loss: 0.8360 - val_accuracy: 0.6326\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.7395 - accuracy: 0.7061 - val_loss: 0.9252 - val_accuracy: 0.7028\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6751 - accuracy: 0.7201 - val_loss: 0.5091 - val_accuracy: 0.7459\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5396 - accuracy: 0.7392 - val_loss: 0.5136 - val_accuracy: 0.7449\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.7446 - val_loss: 0.5028 - val_accuracy: 0.7517\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7494 - val_loss: 0.6798 - val_accuracy: 0.6646\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5441 - accuracy: 0.7349 - val_loss: 0.5710 - val_accuracy: 0.7439\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5820 - accuracy: 0.7251 - val_loss: 0.8519 - val_accuracy: 0.7067\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.0159 - accuracy: 0.6900 - val_loss: 1.5273 - val_accuracy: 0.6070\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.8577 - accuracy: 0.7053 - val_loss: 0.6104 - val_accuracy: 0.7028\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5651 - accuracy: 0.7413 - val_loss: 0.4957 - val_accuracy: 0.7585\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7536 - val_loss: 0.5507 - val_accuracy: 0.7498\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.5402 - accuracy: 0.7386 - val_loss: 0.4920 - val_accuracy: 0.7565\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.5260 - accuracy: 0.7482 - val_loss: 0.4885 - val_accuracy: 0.7628\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.6397 - accuracy: 0.7257 - val_loss: 0.5044 - val_accuracy: 0.7565\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5598 - accuracy: 0.7415 - val_loss: 0.5442 - val_accuracy: 0.7541\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.5737 - accuracy: 0.7363 - val_loss: 0.5055 - val_accuracy: 0.7575\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.5208 - accuracy: 0.7507 - val_loss: 0.4898 - val_accuracy: 0.7633\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5386 - accuracy: 0.7432 - val_loss: 0.6833 - val_accuracy: 0.7333\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6420 - accuracy: 0.7277 - val_loss: 0.8848 - val_accuracy: 0.6452\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.7332 - accuracy: 0.7119 - val_loss: 1.0990 - val_accuracy: 0.6331\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5472 - accuracy: 0.7455 - val_loss: 0.4852 - val_accuracy: 0.7619\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6457 - accuracy: 0.7272 - val_loss: 0.7111 - val_accuracy: 0.7318\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5663 - accuracy: 0.7390 - val_loss: 0.8490 - val_accuracy: 0.6568\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5768 - accuracy: 0.7414 - val_loss: 0.6054 - val_accuracy: 0.7420\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.7375 - val_loss: 0.4900 - val_accuracy: 0.7667\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5607 - accuracy: 0.7415 - val_loss: 0.5309 - val_accuracy: 0.7594\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.7469 - val_loss: 0.5123 - val_accuracy: 0.7536\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.7224 - val_loss: 1.0718 - val_accuracy: 0.6360\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.7312 - val_loss: 0.5468 - val_accuracy: 0.7323\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5684 - accuracy: 0.7435 - val_loss: 0.6291 - val_accuracy: 0.6960\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7493 - val_loss: 0.7471 - val_accuracy: 0.7280\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.7389 - val_loss: 0.5572 - val_accuracy: 0.7531\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7547 - val_loss: 0.7258 - val_accuracy: 0.6742\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5517 - accuracy: 0.7441 - val_loss: 0.5139 - val_accuracy: 0.7628\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7544 - val_loss: 0.7425 - val_accuracy: 0.6747\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5939 - accuracy: 0.7301 - val_loss: 0.7495 - val_accuracy: 0.7275\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.6402 - accuracy: 0.7315 - val_loss: 0.4907 - val_accuracy: 0.7628\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7484 - val_loss: 0.5013 - val_accuracy: 0.7614\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.6563 - accuracy: 0.7280 - val_loss: 1.1117 - val_accuracy: 0.6404\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.0202 - accuracy: 0.6892 - val_loss: 1.0069 - val_accuracy: 0.6462\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5771 - accuracy: 0.7427 - val_loss: 0.5214 - val_accuracy: 0.7473\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7591 - val_loss: 0.5979 - val_accuracy: 0.7178\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.7291 - val_loss: 0.7555 - val_accuracy: 0.6834\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7478 - val_loss: 0.5014 - val_accuracy: 0.7623\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7496 - val_loss: 0.6500 - val_accuracy: 0.7333\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7586 - val_loss: 0.4814 - val_accuracy: 0.7696\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.7546 - val_loss: 0.4985 - val_accuracy: 0.7652\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.7416 - val_loss: 0.4818 - val_accuracy: 0.7715\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5103 - accuracy: 0.7557 - val_loss: 0.4805 - val_accuracy: 0.7769\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5442 - accuracy: 0.7519 - val_loss: 0.5629 - val_accuracy: 0.7512\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7599 - val_loss: 0.5927 - val_accuracy: 0.7493\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7529 - val_loss: 0.4883 - val_accuracy: 0.7749\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5949 - accuracy: 0.7393 - val_loss: 0.4837 - val_accuracy: 0.7793\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7534 - val_loss: 0.5218 - val_accuracy: 0.7701\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5728 - accuracy: 0.7424 - val_loss: 0.4986 - val_accuracy: 0.7691\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.7369 - val_loss: 1.1466 - val_accuracy: 0.6379\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.6409 - accuracy: 0.7318 - val_loss: 0.4831 - val_accuracy: 0.7773\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5614 - accuracy: 0.7479 - val_loss: 0.4790 - val_accuracy: 0.7759\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5453 - accuracy: 0.7496 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7587 - val_loss: 0.8784 - val_accuracy: 0.6621\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5791 - accuracy: 0.7450 - val_loss: 0.4882 - val_accuracy: 0.7730\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7587 - val_loss: 0.4780 - val_accuracy: 0.7720\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.7361 - val_loss: 0.4818 - val_accuracy: 0.7744\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5997 - accuracy: 0.7401 - val_loss: 0.5937 - val_accuracy: 0.7493\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5601 - accuracy: 0.7460 - val_loss: 0.6072 - val_accuracy: 0.7144\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7518 - val_loss: 0.5667 - val_accuracy: 0.7323\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5690 - accuracy: 0.7446 - val_loss: 0.6257 - val_accuracy: 0.7464\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7490 - val_loss: 0.6328 - val_accuracy: 0.7110\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7435 - val_loss: 0.5718 - val_accuracy: 0.7522\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7433 - val_loss: 0.7712 - val_accuracy: 0.6801\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7437 - val_loss: 0.5943 - val_accuracy: 0.7488\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7619 - val_loss: 0.6144 - val_accuracy: 0.7449\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7535 - val_loss: 0.4789 - val_accuracy: 0.7836\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7507 - val_loss: 0.5064 - val_accuracy: 0.7711\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7593 - val_loss: 0.4835 - val_accuracy: 0.7783\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7366 - val_loss: 0.9678 - val_accuracy: 0.6554\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7430 - val_loss: 0.4897 - val_accuracy: 0.7730\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7452 - val_loss: 0.5656 - val_accuracy: 0.7575\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7579 - val_loss: 0.7852 - val_accuracy: 0.7212\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.7311 - val_loss: 0.8794 - val_accuracy: 0.7241\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.7358 - val_loss: 0.4960 - val_accuracy: 0.7740\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7581 - val_loss: 0.5394 - val_accuracy: 0.7459\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7517 - val_loss: 0.5182 - val_accuracy: 0.7696\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5186 - accuracy: 0.7590 - val_loss: 0.7374 - val_accuracy: 0.6868\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.7333 - val_loss: 0.7977 - val_accuracy: 0.6781\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7513 - val_loss: 0.4833 - val_accuracy: 0.7788\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5258 - accuracy: 0.7538 - val_loss: 0.4861 - val_accuracy: 0.7740\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7512 - val_loss: 0.5260 - val_accuracy: 0.7667\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.8618 - accuracy: 0.7177 - val_loss: 0.5139 - val_accuracy: 0.7599\n",
      "65/65 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)\n",
    "predictions = ANN(X_train, y_train, X_test, y_test, weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.64      0.73      1033\n",
      "           1       0.71      0.88      0.79      1033\n",
      "\n",
      "    accuracy                           0.76      2066\n",
      "   macro avg       0.78      0.76      0.76      2066\n",
      "weighted avg       0.78      0.76      0.76      2066\n",
      "\n",
      "[[660 373]\n",
      " [123 910]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20a9e06a1eee47c4abbed4ec8225ad91d78d9800d202b71b6b0a6e47016c6abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
